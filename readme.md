# Awesome Multi-Agent Systems for Audio-Visual Generation and Understanding

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
[![GitHub Stars](https://img.shields.io/github/stars/your-username/your-repo.svg)](https://github.com/your-username/your-repo/stargazers)
[![Contributions Welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

A comprehensive collection of research papers and open-source projects on **Multi-Agent Systems (MAS)** for audio-visual generation and understanding, covering *music, speech, video, image, 3D, and multimodal applications*.

> **Note**: This repository is maintained for academic research purposes. If you find any errors or missing papers, please feel free to contribute via PR or Issue!

---

## üìö Table of Contents

- [üîä Audio Generation & Understanding](#-audio-generation--understanding)
  - [Music Generation & Understanding](#music-generation--understanding)
  - [Speech/Audio Generation](#speechaudio-generation)
  - [Audio Understanding](#audio-understanding)
- [üé¨ Video Generation & Understanding](#-video-generation--understanding)
  - [Video Generation](#video-generation)
  - [Video Understanding](#video-understanding)
  - [Video Editing](#video-editing)
- [üñºÔ∏è Image Generation & Editing](#%EF%B8%8F-image-generation--editing)
  - [Image Generation](#image-generation)
  - [Image Editing](#image-editing)
  - [Image Enhancement](#image-enhancement)
- [üéÆ 3D Content Generation](#-3d-content-generation)
- [üéØ Multimodal & Audio-Visual Systems](#-multimodal--audio-visual-systems)
- [üõ†Ô∏è Data & Tools](#%EF%B8%8F-data--tools)
- [üìä Stats Overview](#-stats-overview)
- [ü§ù Contributing](#-contributing)
- [üìÑ License](#-license)
- [üìñ Citation](#-citation)

---

## üîä Audio Generation & Understanding

### Music Generation & Understanding

| Paper Title | Time | Paper Link | GitHub Link | Task |
| :--- | :--- | :--- | :--- | :--- |
| **TalkPlayData 2: An Agentic Synthetic Data Pipeline for Multimodal Conversational Music Recommendation** | 2025.8 | [arXiv](https://arxiv.org/abs/2509.09685) | [Code](https://github.com/talkpl-ai/talkplaydata-2) | Data Generation |
| **An Agent-Based Framework for Automated Higher-Voice Harmony Generation** | 2025.9 | [arXiv](https://arxiv.org/abs/2509.24463) | NA | Harmony Generation |
| **Musical Agent Systems: MACAT and MACataRT** | 2025.1 | [arXiv](https://arxiv.org/abs/2502.00023) | [Code](https://github.com/Metacreation-Lab/Musical-Agent-Systems) | Music Generation |
| **COMPOSERX: Multi-Agent Symbolic Music Composition with LLMs** | 2024.4 | [arXiv](https://arxiv.org/abs/2404.18081) | [Code](https://github.com/lllindsey0615/ComposerX) | Music Generation |
| **MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models** | 2023.11 | [arXiv](https://arxiv.org/pdf/2310.11954) | [Code](https://github.com/microsoft/muzic/tree/main/musicagent) | Music Generation |

### Speech/Audio Generation

| Paper Title | Time | Paper Link | GitHub Link | Task |
| :--- | :--- | :--- | :--- | :--- |
| **AudioGenie: A Training-Free Multi-Agent Framework for Diverse Multimodality-to-Multiaudio Generation** | 2025.5 | [arXiv](https://arxiv.org/abs/2505.22053) | [Code](https://github.com/ryysayhi/AudioGenie) | Multi-Audio Generation |
| **ReelWave: Multi-Agentic Movie Sound Generation through Multimodal LLM Conversation** | 2025.3 | [arXiv](https://arxiv.org/abs/2503.07217) | NA | Multi-Audio Generation |
| **Dopamine Audiobook: A Training-free MLLM Agent for Emotional and Immersive Audiobook Generation** | 2025.4 | [arXiv](https://arxiv.org/abs/2504.11002) | NA | Multi-Audio Generation |
| **DialogueAgents: A Hybrid Agent-Based Speech Synthesis Framework for Multi-Party Dialogue** | 2025.4 | [arXiv](https://arxiv.org/abs/2504.14482) | [Code](https://github.com/uirlx/DialogueAgents) | Audio Generation |
| **A Multi-Agent AI Framework for Immersive Audiobook Production through Spatial Audio and Neural Narration** | 2025.5 | [arXiv](https://arxiv.org/abs/2505.04885) | NA | Audio Generation |
| **Long-Video Audio Synthesis with Multi-Agent Collaboration** | 2025.5 | [arXiv](https://arxiv.org/abs/2503.10719) | [Code](https://github.com/ZYH-Lightyear/LVAS) | Multi-Audio Generation |
| **Audio-Agent: Leveraging LLMs For Audio Generation, Editing and Composition** | 2024.1 | [arXiv](https://arxiv.org/abs/2410.03335) | NA | Audio Generation |
| **WavCraft: Audio Editing and Generation with Large Language Models** | 2024.3 | [arXiv](https://arxiv.org/abs/2403.09527) | [Code](https://github.com/JinhuaLiang/WavCraft) | Audio Generation & Editing |
| **SpeechAgents: Human-Communication Simulation with Multi-Modal Multi-Agent Systems** | 2024.1 | [arXiv](https://arxiv.org/abs/2401.03945) | [Code](https://github.com/0nutation/SpeechAgents) | Audio Generation |
| **WavJourney: Compositional Audio Creation with Large Language Models** | 2023.7 | [arXiv](https://arxiv.org/abs/2307.14335) | [Code](https://github.com/Audio-AGI/WavJourney) | Multi-Audio Generation |
| **Multi-agent based Arabic speech synthesis** | 2022.5 | [Springer](https://link.springer.com/article/10.1007/s10772-022-09975-8) | NA | Audio Generation |

### Audio Understanding

| Paper Title | Time | Paper Link | GitHub Link | Task |
| :--- | :--- | :--- | :--- | :--- |
| **AudioGenie-Reasoner: A Training-Free Multi-Agent Framework for Coarse-to-Fine Audio Deep Reasoning** | 2025.9 | [arXiv](https://arxiv.org/abs/2509.16971) | [Code](https://github.com/ryysayhi/AudioGenie-Reasoner) | Audio Understanding |
| **AudioToolAgent: An Agentic Framework for Audio-Language Models** | 2025.1 | [arXiv](https://arxiv.org/abs/2510.02995) | [Code](https://github.com/GLJS/AudioToolAgent) | Audio Understanding |

---

## üé¨ Video Generation & Understanding

### Video Generation

| Paper Title | Time | Paper Link | GitHub Link | Task |
| :--- | :--- | :--- | :--- | :--- |
| **Code2Video: A Code-centric Paradigm for Educational Video Generation** | 2025.11 | [arXiv](https://arxiv.org/abs/2510.01174) | [Code](https://github.com/showlab/Code2Video/) | Video Generation |
| **MotionAgent: Fine-grained Controllable Video Generation via Motion Field Agent** | 2025.2 | [arXiv](https://arxiv.org/abs/2502.03207) | [Code](https://github.com/leoisufa/MotionAgent) | Video Generation |
| **PreGenie: An Agentic Framework for High-quality Visual Presentation Generation** | 2025.5 | [arXiv](https://arxiv.org/abs/2505.21660) | NA | Visual Presentation Generation |
| **SPAgent: Adaptive Task Decomposition and Model Selection for General Video Generation and Editing** | 2024.11 | [arXiv](https://arxiv.org/abs/2411.18983) | NA | Video Generation & Editing |
| **PhyT2V: LLM-Guided Iterative Self-Refinement for Physics-Grounded Text-to-Video Generation** | 2024.12 | [arXiv](https://arxiv.org/abs/2412.00596) | NA | Video Generation |
| **GenMAC: Compositional Text-to-Video Generation with Multi-Agent Collaboration** | 2024.12 | [arXiv](https://arxiv.org/abs/2412.04440) | [Code](https://github.com/Karine-Huang/GenMAC) | Video Generation |
| **Mora: Enabling Generalist Video Generation via A Multi-Agent Framework** | 2024.3 | [arXiv](https://arxiv.org/abs/2403.13248) | [Code](https://github.com/lichao-sun/Mora) | Video Generation |

### Video Understanding

| Paper Title | Time | Paper Link | GitHub Link | Task |
| :--- | :--- | :--- | :--- | :--- |
| **VideoLucy: Deep Memory Backtracking for Long Video Understanding** | 2025.10 | [arXiv](https://arxiv.org/abs/2510.12422) | NA | Video Understanding |
| **Cued-Agent: A Collaborative Multi-Agent System for Automatic Cued Speech Recognition** | 2025.8 | [arXiv](https://arxiv.org/abs/2508.00391) | NA | Video Understanding |
| **StreamAgent: Towards Anticipatory Agents for Streaming Video Understanding** | 2025.8 | [arXiv](https://arxiv.org/abs/2508.01875) | NA | Video Understanding |
| **FineQuest: Adaptive Knowledge-Assisted Sports Video Understanding via Agent-of-Thoughts Reasoning** | 2025.9 | [arXiv](https://arxiv.org/abs/2509.11796) | NA | Video Understanding |
| **CAViAR: Critic-Augmented Video Agentic Reasoning** | 2025.9 | [arXiv](https://arxiv.org/abs/2509.07680) | NA | Video Understanding |
| **MASR: Self-Reflective Reasoning through Multimodal Hierarchical Attention Focusing for Agent-based Video Understanding** | 2025.4 | [arXiv](https://arxiv.org/abs/2504.17213) | NA | Video Understanding |
| **ViQAgent: Zero-Shot Video Question Answering via Agent with Open-Vocabulary Grounding Validation** | 2025.5 | [arXiv](https://arxiv.org/abs/2505.15928) | [Code](https://github.com/t-montes/viqagent) | Video Understanding |
| **VideoForest: Person-Anchored Hierarchical Reasoning for Cross-Video Question Answering** | 2025.8 | [arXiv](https://arxiv.org/abs/2508.03039) | [Code](https://github.com/liriar/VideoForest) | Video Understanding |
| **MUPA: Towards Multi-Path Agentic Reasoning for Grounded Video Question Answering** | 2025.6 | [arXiv](https://arxiv.org/abs/2506.18071) | NA | Video Understanding |
| **LVAgent: Long Video Understanding by Multi-Round Dynamical Collaboration of MLLM Agents** | 2025.3 | [arXiv](https://arxiv.org/abs/2503.10200) | NA | Video Understanding |
| **VideoChat-A1: Thinking with Long Videos by Chain-of-Shot Reasoning** | 2025.6 | [arXiv](https://arxiv.org/abs/2506.06097) | NA | Video Understanding |
| **VideoAgent2: Enhancing the LLM-Based Agent System for Long-Form Video Understanding by Uncertainty-Aware CoT** | 2025.4 | [arXiv](https://arxiv.org/abs/2504.04471) | NA | Video Understanding |
| **VideoMultiAgents: A Multi-Agent Framework for Video Question Answering** | 2025.4 | [arXiv](https://arxiv.org/abs/2504.20091) | [Code](https://github.com/taco-group/4KAgent) | Video Understanding |
| **VideoTree: Adaptive Tree-based Video Representation for LLM Reasoning on Long Videos** | 2024.5 | [arXiv](https://arxiv.org/abs/2405.19209) | [Code](https://github.com/Ziyang412/VideoTree) | Video Understanding |
| **Empowering Agentic Video Analytics Systems with Video Language Models** | 2025.5 | [arXiv](https://arxiv.org/abs/2505.00254) | NA | Video Understanding |
| **DrVideo: Document Retrieval Based Long Video Understanding** | 2024.6 | [arXiv](https://arxiv.org/abs/2406.12846) | NA | Video Understanding |
| **VideoAgent: Long-form Video Understanding with Large Language Model as Agent** | 2024.3 | [arXiv](https://arxiv.org/abs/2403.10517) | [Code](https://github.com/YueFan1014/VideoAgent) | Video Understanding |
| **Adaptive Video Understanding Agent: Enhancing efficiency with dynamic frame sampling and feedback-driven reasoning** | 2024.1 | [arXiv](https://arxiv.org/abs/2410.20252) | NA | Video Understanding |
| **VCA: Video Curious Agent for Long Video Understanding** | 2024.12 | [arXiv](https://arxiv.org/abs/2412.10471) | NA | Video Understanding |
| **VDMA: Video Question Answering with Dynamically Generated Multi-Agents** | 2024.7 | [arXiv](https://arxiv.org/abs/2407.03610) | NA | Video Understanding |

### Video Editing

| Paper Title | Time | Paper Link | GitHub Link | Task |
| :--- | :--- | :--- | :--- | :--- |
| **EditDuet: A Multi-Agent System for Video Non-Linear Editing** | 2025.7 | [ACM](https://dl.acm.org/doi/full/10.1145/3721238.3730761) | NA | Video Editing |

---

## üñºÔ∏è Image Generation & Editing

### Image Generation

| Paper Title | Time | Paper Link | GitHub Link | Task |
| :--- | :--- | :--- | :--- | :--- |
| **Draw ALL Your Imagine: A Holistic Benchmark and Agent Framework for Complex Instruction-based Image Generation** | 2025.5 | [arXiv](https://arxiv.org/abs/2505.24787) | [Code](https://github.com/yczhou001/LongBench-T2I) | Image Generation |
| **Talk2Image: A Multi-Agent System for Multi-Turn Image Generation and Editing** | 2025.8 | [arXiv](https://arxiv.org/abs/2508.06916) | NA | Image Generation & Editing |
| **T2I-Copilot: A Training-Free Multi-Agent Text-to-Image System for Enhanced Prompt Interpretation and Interactive Generation** | 2025.7 | [arXiv](https://arxiv.org/abs/2507.20536) | [Code](https://github.com/SHI-Labs/T2I-Copilot) | Image Generation |
| **BannerAgency: Advertising Banner Design with Multimodal LLM Agents** | 2025.3 | [arXiv](https://arxiv.org/abs/2503.11060) | NA | Image Generation |
| **AgentStory: A Multi-Agent System for Story Visualization with Multi-Subject Consistent Text-to-Image Generation** | 2025.6 | [ACM](https://dl.acm.org/doi/pdf/10.1145/3731715.3733271) | [Code](https://github.com/tc2000731/AgentStory) | Image Generation |
| **LayerCraft: Enhancing Text-to-Image Generation with CoT Reasoning and Layered Object Integration** | 2025.1 | [arXiv](https://arxiv.org/abs/2504.00010) | [Code](https://github.com/PeterYYZhang/LayerCraft) | Image Generation |
| **CREA: A Collaborative Multi-Agent Framework for Creative Content Generation with Diffusion Models** | 2025.4 | [arXiv](https://arxiv.org/abs/2504.05306) | NA | Image Generation |
| **StoryAgent: Customized Storytelling Video Generation via Multi-Agent Collaboration** | 2024.11 | [arXiv](https://arxiv.org/abs/2411.04925) | NA | Image Generation |
| **Audit & Repair: An Agentic Framework for Consistent Story Visualization in Text-to-Image Diffusion Models** | 2025.6 | [arXiv](https://arxiv.org/abs/2506.18900) | NA | Image Generation |
| **Multi-Agent Data Visualization and Narrative Generation** | 2025.8 | [arXiv](https://arxiv.org/abs/2509.00481) | NA | Image Generation |
| **GenArtist: Multimodal LLM as an Agent for Unified Image Generation and Editing** | 2024.7 | [arXiv](https://arxiv.org/abs/2407.05600) | [Code](https://github.com/zhenyuw16/GenArtist) | Image Generation & Editing |
| **MUSES: 3D-Controllable Image Generation via Multi-Modal Agent Collaboration** | 2024.8 | [arXiv](https://arxiv.org/abs/2408.10605) | [Code](https://github.com/DINGYANB/MUSES) | Image Generation |
| **DiffusionGPT: LLM-Driven Text-to-Image Generation System** | 2024.1 | [arXiv](https://arxiv.org/abs/2401.10061) | [Code](https://github.com/DiffusionGPT/DiffusionGPT) | Image Generation |
| **VisAgent: Narrative-Preserving Story Visualization Framework** | 2025.3 | [arXiv](https://arxiv.org/abs/2503.02399) | NA | Image Generation |

### Image Editing

| Paper Title | Time | Paper Link | GitHub Link | Task |
| :--- | :--- | :--- | :--- | :--- |
| **Lego-Edit: A General Image Editing Framework with Model-Level Bricks and MLLM Builder** | 2025.9 | [arXiv](https://arxiv.org/abs/2509.12883) | [Code](https://github.com/xiaomi-research/lego-edit) | Image Editing |
| **An LLM-LVLM Driven Agent for Iterative and Fine-Grained Image Editing** | 2025.8 | [arXiv](https://arxiv.org/abs/2508.17435) | NA | Image Editing |
| **EmoAgent: A Multi-Agent Framework for Diverse Affective Image Manipulation** | 2025.3 | [arXiv](https://arxiv.org/abs/2503.11290) | NA | Image Manipulation |
| **Multimodal-LLM Agent For Text-Driven Multi-Attribute Face Editing** | 2025.4 | [IEEE](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=11084332) | NA | Face Editing |

### Image Enhancement

| Paper Title | Time | Paper Link | GitHub Link | Task |
| :--- | :--- | :--- | :--- | :--- |
| **UniShield: An Adaptive Multi-Agent Framework for Unified Forgery Image Detection and Localization** | 2025.10 | [arXiv](https://arxiv.org/abs/2510.03161) | NA | Image Detection & Localization |
| **Comp-X: On Defining an Interactive Learned Image Compression Paradigm With Expert-driven LLM Agent** | 2025.8 | [arXiv](https://arxiv.org/abs/2508.15243) | NA | Image Compression |
| **4KAgent: Agentic Any Image to 4K Super-Resolution** | 2025.7 | [arXiv](https://arxiv.org/abs/2507.07105) | [Code](https://github.com/taco-group/4KAgent) | Image Super-Resolution |

---

## üéÆ 3D Content Generation

| Paper Title | Time | Paper Link | GitHub Link | Task |
| :--- | :--- | :--- | :--- | :--- |
| **Agentic 3D Scene Generation with Spatially Contextualized VLMs** | 2025.5 | [arXiv](https://arxiv.org/abs/2505.20129) | NA | 3D Generation |
| **WorldCraft: Photo-Realistic 3D World Creation and Customization via LLM Agents** | 2025.2 | [arXiv](https://arxiv.org/abs/2502.15601) | NA | 3D Generation |

---

## üéØ Multimodal & Audio-Visual Systems

### Audio-Visual Generation

| Paper Title | Time | Paper Link | GitHub Link | Task |
| :--- | :--- | :--- | :--- | :--- |
| **VISTA: A Test-Time Self-Improving Video Generation Agent** | 2025.10 | [arXiv](https://arxiv.org/abs/2510.15831) | NA | Audio-Visual Generation |
| **FilMaster: Bridging Cinematic Principles and Generative AI for Automated Film Generation** | 2025.6 | [arXiv](https://arxiv.org/abs/2506.18899) | NA | Audio-Visual Generation |
| **AniME: Adaptive Multi-Agent Planning for Long Animation Generation** | 2025.8 | [arXiv](https://arxiv.org/abs/2508.18781) | NA | Audio-Visual Generation |
| **MAViS: A Multi-Agent Framework for Long-Sequence Video Storytelling** | 2025.8 | [arXiv](https://arxiv.org/abs/2508.08487) | NA | Audio-Visual Generation |
| **Automated Movie Generation via Multi-Agent CoT Planning** | 2025.3 | [arXiv](https://arxiv.org/pdf/2503.07314) | [Code](https://github.com/showlab/MovieAgent) | Audio-Visual Generation |
| **Anim-Director: A Large Multimodal Model Powered Agent for Controllable Animation Video Generation** | 2024.8 | [arXiv](https://arxiv.org/abs/2408.09787) | [Code](https://github.com/HITsz-TMG/Anim-Director) | Audio-Visual Generation |
| **Long-Video Audio Synthesis with Multi-Agent Collaboration** | 2025.5 | [arXiv](https://arxiv.org/abs/2503.10719) | [Code](https://github.com/ZYH-Lightyear/LVAS) | Multi-Audio Generation |
| **Toward Low-Latency End-to-End Voice Agents for Telecommunications Using Streaming ASR, Quantized LLMs, and Real-Time TTS** | 2025.8 | [arXiv](https://arxiv.org/abs/2508.04721) | NA | Voice Agent |

### Presentation & Educational Video

| Paper Title | Time | Paper Link | GitHub Link | Task |
| :--- | :--- | :--- | :--- | :--- |
| **Paper2Video: Automatic Video Generation from Scientific Papers** | 2025.10 | [arXiv](https://arxiv.org/abs/2510.05096) | [Code](https://github.com/showlab/Paper2Video) | Presentation Video |
| **Preacher: Paper-to-Video Agentic System** | 2025.8 | [arXiv](https://arxiv.org/abs/2508.09632) | [Code](https://github.com/Gen-Verse/Paper2Video) | Presentation Video |
| **PresentAgent: Multimodal Agent for Presentation Video Generation** | 2025.7 | [arXiv](https://arxiv.org/abs/2507.04036) | [Code](https://github.com/AIGeeksGroup/PresentAgent) | Presentation Video |
| **Code2Video: A Code-centric Paradigm for Educational Video Generation** | 2025.11 | [arXiv](https://arxiv.org/abs/2510.01174) | [Code](https://github.com/showlab/Code2Video/) | Educational Video |
| **From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework for Reasoning-Driven Pedagogical Visualization** | 2025.5 | [arXiv](https://arxiv.org/abs/2505.16832) | [Code](https://github.com/aiming-lab/EduVisAgent) | Education Visualization |
| **Presenting a Paper is an Art: Self-Improvement Aesthetic Agents for Academic Presentations** | 2025.11 | [arXiv](https://arxiv.org/abs/2510.05571) | [Code](https://github.com/eric-ai-lab/EvoPresent) | Presentation |

### Unified & Story Systems

| Paper Title | Time | Paper Link | GitHub Link | Task |
| :--- | :--- | :--- | :--- | :--- |
| **A Unified Multi-Agent Framework for Universal Multimodal Understanding and Generation** | 2025.8 | [arXiv](https://arxiv.org/abs/2508.10494) | NA | Multimodal Understanding & Generation |
| **FilmAgent: A Multi-Agent Framework for End-to-End Film Automation in Virtual 3D Spaces** | 2025.1 | [arXiv](https://arxiv.org/abs/2501.12909) | [Code](https://github.com/HITsz-TMG/FilmAgent) | Film Generation |
| **PersonaVlog: Personalized Multimodal Vlog Generation with Multi-Agent Collaboration and Iterative Self-Correction** | 2025.8 | [arXiv](https://arxiv.org/abs/2508.13602) | NA | Vlog Generation |
| **MM-StoryAgent: Immersive Narrated Storybook Video Generation with a Multi-Agent Paradigm across Text, Image and Audio** | 2025.3 | [arXiv](https://arxiv.org/abs/2503.05242) | [Code](https://github.com/X-PLUG/MM_StoryAgent) | Story Generation |

---

## üõ†Ô∏è Data & Tools

| Paper Title | Time | Paper Link | GitHub Link | Task |
| :--- | :--- | :--- | :--- | :--- |
| **TalkPlayData 2: An Agentic Synthetic Data Pipeline for Multimodal Conversational Music Recommendation** | 2025.8 | [arXiv](https://arxiv.org/abs/2509.09685) | [Code](https://github.com/talkpl-ai/talkplaydata-2) | Data Pipeline |

---

## üìä Stats Overview

| Category | Papers | With Code | Code Rate |
| :--- | :--- | :--- | :--- |
| **Audio** | 15 | 7 | 46.7% |
| **Video** | 23 | 6 | 26.1% |
| **Image** | 17 | 8 | 47.1% |
| **3D** | 2 | 0 | 0% |
| **Multimodal** | 11 | 5 | 45.5% |
| **Total** | **68** | **26** | **38.2%** |

*Last Updated: 2025-11-11*

---

## üìÑ License

This repository is released under the [MIT License](LICENSE). All paper contents and code belong to their respective authors.

---

## üìñ Citation

If you find this repository useful, please consider citing:

```bibtex
@misc{awesome_mas_av_repo,
  title={Awesome Multi-Agent Systems for Audio-Visual Generation and Understanding},
  author={Contributors},
  howpublished={\url{https://github.com/your-username/your-repo}},
  year={2025}
}
```

---

## üåü Star History

[![Star History Chart](https://api.star-history.com/svg?repos=your-username/your-repo&type=Date)](https://star-history.com/#your-username/your-repo&Date)

**Disclaimer**: This is a community-maintained repository for academic purposes. All trademarks and copyrights belong to their respective owners.

---

<div align="center">
  <sub>Built with ‚ù§Ô∏è by the MAS Community | Last Updated: 2025-11-11</sub>
</div>
